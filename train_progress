Model 1

Epoch 1

loss: 4.682214, 32.000000/50000.000000
loss: 4.006253, 352.000000/50000.000000
loss: 4.004165, 672.000000/50000.000000
loss: 4.008071, 992.000000/50000.000000
loss: 4.025258, 1312.000000/50000.000000
loss: 4.061196, 1632.000000/50000.000000
loss: 3.997914, 1952.000000/50000.000000
loss: 3.987758, 2272.000000/50000.000000
loss: 4.038539, 2592.000000/50000.000000
loss: 4.038539, 2912.000000/50000.000000
loss: 4.050258, 3232.000000/50000.000000
loss: 4.046352, 3552.000000/50000.000000
loss: 4.076039, 3872.000000/50000.000000
loss: 4.000258, 4192.000000/50000.000000
loss: 4.022133, 4512.000000/50000.000000
loss: 4.019008, 4832.000000/50000.000000
loss: 4.047133, 5152.000000/50000.000000
loss: 4.018227, 5472.000000/50000.000000
loss: 3.974477, 5792.000000/50000.000000
loss: 3.976039, 6112.000000/50000.000000
loss: 4.059633, 6432.000000/50000.000000
loss: 3.997133, 6752.000000/50000.000000
loss: 3.996352, 7072.000000/50000.000000
loss: 3.990883, 7392.000000/50000.000000
loss: 4.010415, 7712.000000/50000.000000
loss: 4.016665, 8032.000000/50000.000000
loss: 4.069789, 8352.000000/50000.000000
loss: 4.022133, 8672.000000/50000.000000
loss: 3.997133, 8992.000000/50000.000000
loss: 4.029164, 9312.000000/50000.000000
loss: 4.059633, 9632.000000/50000.000000
loss: 4.011977, 9952.000000/50000.000000
loss: 4.038539, 10272.000000/50000.000000
loss: 4.008852, 10592.000000/50000.000000
loss: 4.020571, 10912.000000/50000.000000
loss: 4.051821, 11232.000000/50000.000000
loss: 4.036196, 11552.000000/50000.000000
loss: 4.056508, 11872.000000/50000.000000
loss: 4.004946, 12192.000000/50000.000000
loss: 4.017446, 12512.000000/50000.000000
loss: 3.986196, 12832.000000/50000.000000
loss: 4.044789, 13152.000000/50000.000000
loss: 4.057290, 13472.000000/50000.000000
loss: 4.030727, 13792.000000/50000.000000
loss: 4.013539, 14112.000000/50000.000000
loss: 4.023696, 14432.000000/50000.000000
loss: 3.984633, 14752.000000/50000.000000
loss: 4.042446, 15072.000000/50000.000000
loss: 4.045571, 15392.000000/50000.000000
loss: 4.033852, 15712.000000/50000.000000


Model 2

Epoch 1

loss: 4.681759, 32.000000/59000.000000
loss: 4.671009, 672.000000/59000.000000
loss: 4.672753, 1312.000000/59000.000000
loss: 4.672378, 1952.000000/59000.000000
loss: 4.671399, 2592.000000/59000.000000
loss: 4.671950, 3232.000000/59000.000000
loss: 4.671620, 3872.000000/59000.000000
loss: 4.672243, 4512.000000/59000.000000
loss: 4.671754, 5152.000000/59000.000000
loss: 4.672292, 5792.000000/59000.000000
loss: 4.672182, 6432.000000/59000.000000
loss: 4.671962, 7072.000000/59000.000000
loss: 4.672036, 7712.000000/59000.000000
loss: 4.671926, 8352.000000/59000.000000
loss: 4.672121, 8992.000000/59000.000000
loss: 4.672365, 9632.000000/59000.000000
loss: 4.672133, 10272.000000/59000.000000
loss: 4.672427, 10912.000000/59000.000000
loss: 4.671888, 11552.000000/59000.000000
loss: 4.671766, 12192.000000/59000.000000
loss: 4.671950, 12832.000000/59000.000000
loss: 4.672011, 13472.000000/59000.000000
loss: 4.671362, 14112.000000/59000.000000
loss: 4.671962, 14752.000000/59000.000000
loss: 4.672158, 15392.000000/59000.000000
loss: 4.671680, 16032.000000/59000.000000
loss: 4.672305, 16672.000000/59000.000000
loss: 4.671632, 17312.000000/59000.000000
loss: 4.671840, 17952.000000/59000.000000
loss: 4.671313, 18592.000000/59000.000000
loss: 4.671717, 19232.000000/59000.000000
loss: 4.672072, 19872.000000/59000.000000
loss: 4.672072, 20512.000000/59000.000000
loss: 4.672452, 21152.000000/59000.000000
loss: 4.671926, 21792.000000/59000.000000
loss: 4.671999, 22432.000000/59000.000000
loss: 4.672084, 23072.000000/59000.000000
loss: 4.672133, 23712.000000/59000.000000
loss: 4.671424, 24352.000000/59000.000000
loss: 4.671705, 24992.000000/59000.000000
loss: 4.672341, 25632.000000/59000.000000
loss: 4.672721, 26272.000000/59000.000000
loss: 4.671962, 26912.000000/59000.000000
loss: 4.672329, 27552.000000/59000.000000
loss: 4.672060, 28192.000000/59000.000000
loss: 4.671754, 28832.000000/59000.000000
loss: 4.672451, 29472.000000/59000.000000
loss: 4.671766, 30112.000000/59000.000000
loss: 4.671595, 30752.000000/59000.000000
loss: 4.671595, 31392.000000/59000.000000
loss: 4.671949, 32032.000000/59000.000000
loss: 4.672721, 32672.000000/59000.000000
loss: 4.672770, 33312.000000/59000.000000
loss: 4.672146, 33952.000000/59000.000000
loss: 4.671913, 34592.000000/59000.000000
loss: 4.671717, 35232.000000/59000.000000
loss: 4.672158, 35872.000000/59000.000000
loss: 4.671522, 36512.000000/59000.000000
loss: 4.671999, 37152.000000/59000.000000
loss: 4.672317, 37792.000000/59000.000000
loss: 4.671950, 38432.000000/59000.000000
loss: 4.672206, 39072.000000/59000.000000
loss: 4.671546, 39712.000000/59000.000000
loss: 4.671534, 40352.000000/59000.000000
loss: 4.672060, 40992.000000/59000.000000
loss: 4.671534, 41632.000000/59000.000000
loss: 4.672256, 42272.000000/59000.000000
loss: 4.671595, 42912.000000/59000.000000
loss: 4.672145, 43552.000000/59000.000000
loss: 4.671888, 44192.000000/59000.000000
loss: 4.672366, 44832.000000/59000.000000
loss: 4.672121, 45472.000000/59000.000000
loss: 4.671889, 46112.000000/59000.000000
loss: 4.671754, 46752.000000/59000.000000
loss: 4.671730, 47392.000000/59000.000000
loss: 4.671901, 48032.000000/59000.000000
loss: 4.672048, 48672.000000/59000.000000
loss: 4.672427, 49312.000000/59000.000000
loss: 4.672598, 49952.000000/59000.000000
loss: 4.671705, 50592.000000/59000.000000
loss: 4.671680, 51232.000000/59000.000000
loss: 4.672170, 51872.000000/59000.000000
loss: 4.672390, 52512.000000/59000.000000
loss: 4.672390, 53152.000000/59000.000000
loss: 4.671926, 53792.000000/59000.000000
loss: 4.671546, 54432.000000/59000.000000
loss: 4.672463, 55072.000000/59000.000000
loss: 4.671852, 55712.000000/59000.000000
loss: 4.672097, 56352.000000/59000.000000
loss: 4.671852, 56992.000000/59000.000000
loss: 4.671949, 57632.000000/59000.000000
loss: 4.671729, 58272.000000/59000.000000
loss: 4.671852, 58912.000000/59000.000000
tensor([[107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107]])
Test Error: 
 Accuracy: 68.2%, Avg loss: 4.671967 

Done!
Epoch 2

loss: 4.672035, 32.000000/59000.000000
loss: 4.672206, 672.000000/59000.000000
loss: 4.671631, 1312.000000/59000.000000
loss: 4.671595, 1952.000000/59000.000000
loss: 4.672183, 2592.000000/59000.000000
loss: 4.671191, 3232.000000/59000.000000
loss: 4.671852, 3872.000000/59000.000000
loss: 4.671803, 4512.000000/59000.000000
loss: 4.672219, 5152.000000/59000.000000
loss: 4.671631, 5792.000000/59000.000000
loss: 4.672622, 6432.000000/59000.000000
loss: 4.671987, 7072.000000/59000.000000
loss: 4.671827, 7712.000000/59000.000000
loss: 4.673002, 8352.000000/59000.000000
loss: 4.670825, 8992.000000/59000.000000
loss: 4.672586, 9632.000000/59000.000000
loss: 4.671179, 10272.000000/59000.000000
loss: 4.671779, 10912.000000/59000.000000
loss: 4.672145, 11552.000000/59000.000000
loss: 4.671448, 12192.000000/59000.000000
loss: 4.672818, 12832.000000/59000.000000
loss: 4.671987, 13472.000000/59000.000000
loss: 4.672048, 14112.000000/59000.000000
loss: 4.672084, 14752.000000/59000.000000
loss: 4.671631, 15392.000000/59000.000000
loss: 4.672096, 16032.000000/59000.000000
loss: 4.672145, 16672.000000/59000.000000
loss: 4.671815, 17312.000000/59000.000000
loss: 4.671852, 17952.000000/59000.000000
loss: 4.672133, 18592.000000/59000.000000
loss: 4.672305, 19232.000000/59000.000000
loss: 4.672684, 19872.000000/59000.000000
loss: 4.671448, 20512.000000/59000.000000
loss: 4.672292, 21152.000000/59000.000000
loss: 4.671485, 21792.000000/59000.000000
loss: 4.672354, 22432.000000/59000.000000
loss: 4.671227, 23072.000000/59000.000000
loss: 4.672268, 23712.000000/59000.000000
loss: 4.672170, 24352.000000/59000.000000
loss: 4.671999, 24992.000000/59000.000000
loss: 4.672023, 25632.000000/59000.000000
loss: 4.671766, 26272.000000/59000.000000
loss: 4.672684, 26912.000000/59000.000000
loss: 4.672623, 27552.000000/59000.000000
loss: 4.671913, 28192.000000/59000.000000
loss: 4.671521, 28832.000000/59000.000000
loss: 4.672439, 29472.000000/59000.000000
loss: 4.671778, 30112.000000/59000.000000
loss: 4.672133, 30752.000000/59000.000000
loss: 4.671852, 31392.000000/59000.000000
loss: 4.671595, 32032.000000/59000.000000
loss: 4.672365, 32672.000000/59000.000000
loss: 4.672536, 33312.000000/59000.000000
loss: 4.671558, 33952.000000/59000.000000
loss: 4.671472, 34592.000000/59000.000000
loss: 4.671558, 35232.000000/59000.000000
loss: 4.672549, 35872.000000/59000.000000
loss: 4.672048, 36512.000000/59000.000000
loss: 4.671595, 37152.000000/59000.000000
loss: 4.672635, 37792.000000/59000.000000
loss: 4.672317, 38432.000000/59000.000000
loss: 4.671876, 39072.000000/59000.000000
loss: 4.671606, 39712.000000/59000.000000
loss: 4.672121, 40352.000000/59000.000000
loss: 4.672084, 40992.000000/59000.000000
loss: 4.672157, 41632.000000/59000.000000
loss: 4.672402, 42272.000000/59000.000000
loss: 4.671814, 42912.000000/59000.000000
loss: 4.671545, 43552.000000/59000.000000
loss: 4.672328, 44192.000000/59000.000000
loss: 4.671655, 44832.000000/59000.000000
loss: 4.671837, 45472.000000/59000.000000
loss: 4.672325, 46112.000000/59000.000000
loss: 4.672366, 46752.000000/59000.000000
loss: 4.672109, 47392.000000/59000.000000
loss: 4.671864, 48032.000000/59000.000000
loss: 4.671448, 48672.000000/59000.000000
loss: 4.671937, 49312.000000/59000.000000
loss: 4.672561, 49952.000000/59000.000000
loss: 4.673063, 50592.000000/59000.000000
loss: 4.672194, 51232.000000/59000.000000
loss: 4.672146, 51872.000000/59000.000000
loss: 4.671680, 52512.000000/59000.000000
loss: 4.672390, 53152.000000/59000.000000
loss: 4.672353, 53792.000000/59000.000000
loss: 4.672096, 54432.000000/59000.000000
loss: 4.672341, 55072.000000/59000.000000
loss: 4.672268, 55712.000000/59000.000000
loss: 4.671313, 56352.000000/59000.000000
loss: 4.672243, 56992.000000/59000.000000
loss: 4.671595, 57632.000000/59000.000000
loss: 4.671595, 58272.000000/59000.000000
loss: 4.671828, 58912.000000/59000.000000
tensor([[107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107]])
Test Error: 
 Accuracy: 68.2%, Avg loss: 4.671967 

Done!
Epoch 3

loss: 4.672023, 32.000000/59000.000000
loss: 4.671583, 672.000000/59000.000000
loss: 4.671779, 1312.000000/59000.000000
loss: 4.672194, 1952.000000/59000.000000
loss: 4.672182, 2592.000000/59000.000000
loss: 4.671668, 3232.000000/59000.000000
loss: 4.672476, 3872.000000/59000.000000
loss: 4.672023, 4512.000000/59000.000000
loss: 4.671289, 5152.000000/59000.000000
loss: 4.672207, 5792.000000/59000.000000
loss: 4.671631, 6432.000000/59000.000000
loss: 4.671949, 7072.000000/59000.000000
loss: 4.671913, 7712.000000/59000.000000
loss: 4.672402, 8352.000000/59000.000000
loss: 4.671632, 8992.000000/59000.000000
loss: 4.672500, 9632.000000/59000.000000
loss: 4.672317, 10272.000000/59000.000000
loss: 4.672366, 10912.000000/59000.000000
loss: 4.672121, 11552.000000/59000.000000
loss: 4.672097, 12192.000000/59000.000000
loss: 4.671362, 12832.000000/59000.000000
loss: 4.672023, 13472.000000/59000.000000
loss: 4.671999, 14112.000000/59000.000000
loss: 4.672084, 14752.000000/59000.000000
loss: 4.671864, 15392.000000/59000.000000
loss: 4.671852, 16032.000000/59000.000000
loss: 4.671730, 16672.000000/59000.000000
loss: 4.672097, 17312.000000/59000.000000
loss: 4.672206, 17952.000000/59000.000000
loss: 4.671815, 18592.000000/59000.000000
loss: 4.672182, 19232.000000/59000.000000
loss: 4.672036, 19872.000000/59000.000000
loss: 4.672194, 20512.000000/59000.000000
loss: 4.672060, 21152.000000/59000.000000
loss: 4.672231, 21792.000000/59000.000000
loss: 4.671668, 22432.000000/59000.000000
loss: 4.671717, 23072.000000/59000.000000
loss: 4.672206, 23712.000000/59000.000000
loss: 4.671412, 24352.000000/59000.000000
loss: 4.671546, 24992.000000/59000.000000
loss: 4.672684, 25632.000000/59000.000000
loss: 4.671705, 26272.000000/59000.000000
loss: 4.672206, 26912.000000/59000.000000
loss: 4.671742, 27552.000000/59000.000000
loss: 4.671827, 28192.000000/59000.000000
loss: 4.671399, 28832.000000/59000.000000
loss: 4.671460, 29472.000000/59000.000000
loss: 4.672244, 30112.000000/59000.000000
loss: 4.671815, 30752.000000/59000.000000
loss: 4.671522, 31392.000000/59000.000000
loss: 4.672524, 32032.000000/59000.000000
loss: 4.672121, 32672.000000/59000.000000
loss: 4.671546, 33312.000000/59000.000000
loss: 4.672561, 33952.000000/59000.000000
loss: 4.671950, 34592.000000/59000.000000
loss: 4.671962, 35232.000000/59000.000000
loss: 4.672121, 35872.000000/59000.000000
loss: 4.672096, 36512.000000/59000.000000
loss: 4.672231, 37152.000000/59000.000000
loss: 4.672402, 37792.000000/59000.000000
loss: 4.672048, 38432.000000/59000.000000
loss: 4.671252, 39072.000000/59000.000000
loss: 4.672488, 39712.000000/59000.000000
loss: 4.672023, 40352.000000/59000.000000
loss: 4.672219, 40992.000000/59000.000000
loss: 4.671656, 41632.000000/59000.000000
loss: 4.671496, 42272.000000/59000.000000
loss: 4.672696, 42912.000000/59000.000000
loss: 4.672892, 43552.000000/59000.000000
loss: 4.672427, 44192.000000/59000.000000
loss: 4.672574, 44832.000000/59000.000000
loss: 4.672072, 45472.000000/59000.000000
loss: 4.672708, 46112.000000/59000.000000
loss: 4.672035, 46752.000000/59000.000000
loss: 4.672158, 47392.000000/59000.000000
loss: 4.672194, 48032.000000/59000.000000
loss: 4.671803, 48672.000000/59000.000000
loss: 4.671815, 49312.000000/59000.000000
loss: 4.671840, 49952.000000/59000.000000
loss: 4.672011, 50592.000000/59000.000000
loss: 4.672476, 51232.000000/59000.000000
loss: 4.671607, 51872.000000/59000.000000
loss: 4.671754, 52512.000000/59000.000000
loss: 4.672280, 53152.000000/59000.000000
loss: 4.672084, 53792.000000/59000.000000
loss: 4.672231, 54432.000000/59000.000000
loss: 4.671277, 55072.000000/59000.000000
loss: 4.671619, 55712.000000/59000.000000
loss: 4.672244, 56352.000000/59000.000000
loss: 4.671718, 56992.000000/59000.000000
loss: 4.671913, 57632.000000/59000.000000
loss: 4.671448, 58272.000000/59000.000000
loss: 4.672183, 58912.000000/59000.000000
tensor([[107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107]])
Test Error: 
 Accuracy: 68.2%, Avg loss: 4.671967 

Done!
Epoch 4

loss: 4.671668, 32.000000/59000.000000
loss: 4.672292, 672.000000/59000.000000
loss: 4.671827, 1312.000000/59000.000000
loss: 4.671949, 1952.000000/59000.000000
loss: 4.671779, 2592.000000/59000.000000
loss: 4.672231, 3232.000000/59000.000000
loss: 4.672256, 3872.000000/59000.000000
loss: 4.671240, 4512.000000/59000.000000
loss: 4.671840, 5152.000000/59000.000000
loss: 4.671937, 5792.000000/59000.000000
loss: 4.671790, 6432.000000/59000.000000
loss: 4.672011, 7072.000000/59000.000000
loss: 4.671779, 7712.000000/59000.000000
loss: 4.672219, 8352.000000/59000.000000
loss: 4.672194, 8992.000000/59000.000000
loss: 4.672268, 9632.000000/59000.000000
loss: 4.671975, 10272.000000/59000.000000
loss: 4.671424, 10912.000000/59000.000000
loss: 4.672097, 11552.000000/59000.000000
loss: 4.671643, 12192.000000/59000.000000
loss: 4.671668, 12832.000000/59000.000000
loss: 4.672684, 13472.000000/59000.000000
loss: 4.672341, 14112.000000/59000.000000
loss: 4.671815, 14752.000000/59000.000000
loss: 4.672219, 15392.000000/59000.000000
loss: 4.670836, 16032.000000/59000.000000
loss: 4.672072, 16672.000000/59000.000000
loss: 4.672231, 17312.000000/59000.000000
loss: 4.671264, 17952.000000/59000.000000
loss: 4.671644, 18592.000000/59000.000000
loss: 4.671987, 19232.000000/59000.000000
loss: 4.672317, 19872.000000/59000.000000
loss: 4.672036, 20512.000000/59000.000000
loss: 4.671619, 21152.000000/59000.000000
loss: 4.672769, 21792.000000/59000.000000
loss: 4.672599, 22432.000000/59000.000000
loss: 4.672720, 23072.000000/59000.000000
loss: 4.671791, 23712.000000/59000.000000
loss: 4.672096, 24352.000000/59000.000000
loss: 4.672647, 24992.000000/59000.000000
loss: 4.672194, 25632.000000/59000.000000
loss: 4.672036, 26272.000000/59000.000000
loss: 4.671987, 26912.000000/59000.000000
loss: 4.671534, 27552.000000/59000.000000
loss: 4.671815, 28192.000000/59000.000000
loss: 4.672170, 28832.000000/59000.000000
loss: 4.672072, 29472.000000/59000.000000
loss: 4.671313, 30112.000000/59000.000000
loss: 4.671154, 30752.000000/59000.000000
loss: 4.672770, 31392.000000/59000.000000
loss: 4.671975, 32032.000000/59000.000000
loss: 4.671803, 32672.000000/59000.000000
loss: 4.672071, 33312.000000/59000.000000
loss: 4.671926, 33952.000000/59000.000000
loss: 4.671852, 34592.000000/59000.000000
loss: 4.671338, 35232.000000/59000.000000
loss: 4.671950, 35872.000000/59000.000000
loss: 4.672561, 36512.000000/59000.000000
loss: 4.672574, 37152.000000/59000.000000
loss: 4.671949, 37792.000000/59000.000000
loss: 4.671766, 38432.000000/59000.000000
loss: 4.672366, 39072.000000/59000.000000
loss: 4.671534, 39712.000000/59000.000000
loss: 4.671925, 40352.000000/59000.000000
loss: 4.673234, 40992.000000/59000.000000
loss: 4.672145, 41632.000000/59000.000000
loss: 4.671986, 42272.000000/59000.000000
loss: 4.672304, 42912.000000/59000.000000
loss: 4.672145, 43552.000000/59000.000000
loss: 4.671631, 44192.000000/59000.000000
loss: 4.672121, 44832.000000/59000.000000
loss: 4.672329, 45472.000000/59000.000000
loss: 4.672060, 46112.000000/59000.000000
loss: 4.671644, 46752.000000/59000.000000
loss: 4.672341, 47392.000000/59000.000000
loss: 4.672390, 48032.000000/59000.000000
loss: 4.671705, 48672.000000/59000.000000
loss: 4.671521, 49312.000000/59000.000000
loss: 4.672010, 49952.000000/59000.000000
loss: 4.672769, 50592.000000/59000.000000
loss: 4.671999, 51232.000000/59000.000000
loss: 4.672060, 51872.000000/59000.000000
loss: 4.672097, 52512.000000/59000.000000
loss: 4.671619, 53152.000000/59000.000000
loss: 4.671888, 53792.000000/59000.000000
loss: 4.673332, 54432.000000/59000.000000
loss: 4.671729, 55072.000000/59000.000000
loss: 4.671509, 55712.000000/59000.000000
loss: 4.672610, 56352.000000/59000.000000
loss: 4.671803, 56992.000000/59000.000000
loss: 4.672475, 57632.000000/59000.000000
loss: 4.672622, 58272.000000/59000.000000
loss: 4.672206, 58912.000000/59000.000000
tensor([[107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107]])
Test Error: 
 Accuracy: 68.2%, Avg loss: 4.671967 

Done!
Epoch 5

loss: 4.672183, 32.000000/59000.000000
loss: 4.672390, 672.000000/59000.000000
loss: 4.671729, 1312.000000/59000.000000
loss: 4.672671, 1952.000000/59000.000000
loss: 4.672635, 2592.000000/59000.000000
loss: 4.671803, 3232.000000/59000.000000
loss: 4.671962, 3872.000000/59000.000000
loss: 4.672060, 4512.000000/59000.000000
loss: 4.671998, 5152.000000/59000.000000
loss: 4.671718, 5792.000000/59000.000000
loss: 4.672280, 6432.000000/59000.000000
loss: 4.671619, 7072.000000/59000.000000
loss: 4.672341, 7712.000000/59000.000000
loss: 4.671595, 8352.000000/59000.000000
loss: 4.671729, 8992.000000/59000.000000
loss: 4.671705, 9632.000000/59000.000000
loss: 4.671790, 10272.000000/59000.000000
loss: 4.672366, 10912.000000/59000.000000
loss: 4.672414, 11552.000000/59000.000000
loss: 4.671277, 12192.000000/59000.000000
loss: 4.672011, 12832.000000/59000.000000
loss: 4.671656, 13472.000000/59000.000000
loss: 4.672280, 14112.000000/59000.000000
loss: 4.671558, 14752.000000/59000.000000
loss: 4.671974, 15392.000000/59000.000000
loss: 4.672145, 16032.000000/59000.000000
loss: 4.672207, 16672.000000/59000.000000
loss: 4.672427, 17312.000000/59000.000000
loss: 4.672023, 17952.000000/59000.000000
loss: 4.672109, 18592.000000/59000.000000
loss: 4.672182, 19232.000000/59000.000000
loss: 4.671619, 19872.000000/59000.000000
loss: 4.672328, 20512.000000/59000.000000
loss: 4.671424, 21152.000000/59000.000000
loss: 4.672353, 21792.000000/59000.000000
loss: 4.672341, 22432.000000/59000.000000
loss: 4.672353, 23072.000000/59000.000000
loss: 4.671852, 23712.000000/59000.000000
loss: 4.671913, 24352.000000/59000.000000
loss: 4.671937, 24992.000000/59000.000000
loss: 4.671888, 25632.000000/59000.000000
loss: 4.672072, 26272.000000/59000.000000
loss: 4.672549, 26912.000000/59000.000000
loss: 4.671766, 27552.000000/59000.000000
loss: 4.671852, 28192.000000/59000.000000
loss: 4.671840, 28832.000000/59000.000000
loss: 4.671704, 29472.000000/59000.000000
loss: 4.672488, 30112.000000/59000.000000
loss: 4.671889, 30752.000000/59000.000000
loss: 4.672586, 31392.000000/59000.000000
loss: 4.672439, 32032.000000/59000.000000
loss: 4.672794, 32672.000000/59000.000000
loss: 4.672782, 33312.000000/59000.000000
loss: 4.671705, 33952.000000/59000.000000
loss: 4.671681, 34592.000000/59000.000000
loss: 4.672096, 35232.000000/59000.000000
loss: 4.671644, 35872.000000/59000.000000
loss: 4.671999, 36512.000000/59000.000000
loss: 4.671815, 37152.000000/59000.000000
loss: 4.671204, 37792.000000/59000.000000
loss: 4.672672, 38432.000000/59000.000000
loss: 4.671815, 39072.000000/59000.000000
loss: 4.671937, 39712.000000/59000.000000
loss: 4.671326, 40352.000000/59000.000000
loss: 4.672365, 40992.000000/59000.000000
loss: 4.672048, 41632.000000/59000.000000
loss: 4.672304, 42272.000000/59000.000000
loss: 4.671705, 42912.000000/59000.000000
loss: 4.672256, 43552.000000/59000.000000
loss: 4.672561, 44192.000000/59000.000000
loss: 4.672280, 44832.000000/59000.000000
loss: 4.672048, 45472.000000/59000.000000
loss: 4.671521, 46112.000000/59000.000000
loss: 4.672097, 46752.000000/59000.000000
loss: 4.671509, 47392.000000/59000.000000
loss: 4.672292, 48032.000000/59000.000000
loss: 4.671889, 48672.000000/59000.000000
loss: 4.671987, 49312.000000/59000.000000
loss: 4.671644, 49952.000000/59000.000000
loss: 4.672207, 50592.000000/59000.000000
loss: 4.671950, 51232.000000/59000.000000
loss: 4.672256, 51872.000000/59000.000000
loss: 4.671534, 52512.000000/59000.000000
loss: 4.672121, 53152.000000/59000.000000
loss: 4.671852, 53792.000000/59000.000000
loss: 4.671975, 54432.000000/59000.000000
loss: 4.671987, 55072.000000/59000.000000
loss: 4.672414, 55712.000000/59000.000000
loss: 4.672158, 56352.000000/59000.000000
loss: 4.672414, 56992.000000/59000.000000
loss: 4.672451, 57632.000000/59000.000000
loss: 4.671656, 58272.000000/59000.000000
loss: 4.671938, 58912.000000/59000.000000
tensor([[107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107],
        [107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
         107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107]])
Test Error: 
 Accuracy: 68.2%, Avg loss: 4.671967 

# This falls into the local minimum of 107

# New training
# Model 3
Epoch 1

loss: 4.682639, 32.000000/59000.000000
loss: 4.646352, 672.000000/59000.000000
loss: 4.643227, 1312.000000/59000.000000
loss: 4.644008, 1952.000000/59000.000000
loss: 4.653383, 2592.000000/59000.000000
loss: 4.650258, 3232.000000/59000.000000
loss: 4.649477, 3872.000000/59000.000000
loss: 4.647914, 4512.000000/59000.000000
loss: 4.652602, 5152.000000/59000.000000
loss: 4.637758, 5792.000000/59000.000000
loss: 4.655727, 6432.000000/59000.000000
loss: 4.660415, 7072.000000/59000.000000
loss: 4.650258, 7712.000000/59000.000000
loss: 4.650258, 8352.000000/59000.000000
loss: 4.646352, 8992.000000/59000.000000
loss: 4.659633, 9632.000000/59000.000000
loss: 4.633071, 10272.000000/59000.000000
loss: 4.639321, 10912.000000/59000.000000
loss: 4.647133, 11552.000000/59000.000000
loss: 4.647133, 12192.000000/59000.000000
loss: 4.649477, 12832.000000/59000.000000
loss: 4.651821, 13472.000000/59000.000000
loss: 4.672292, 14112.000000/59000.000000
loss: 4.671791, 14752.000000/59000.000000
loss: 4.671998, 15392.000000/59000.000000
loss: 4.672672, 16032.000000/59000.000000
loss: 4.672585, 16672.000000/59000.000000
loss: 4.672427, 17312.000000/59000.000000
loss: 4.672206, 17952.000000/59000.000000
loss: 4.672097, 18592.000000/59000.000000
loss: 4.671412, 19232.000000/59000.000000
loss: 4.671876, 19872.000000/59000.000000
loss: 4.672096, 20512.000000/59000.000000
loss: 4.672415, 21152.000000/59000.000000
loss: 4.672121, 21792.000000/59000.000000
loss: 4.672341, 22432.000000/59000.000000
loss: 4.671766, 23072.000000/59000.000000
loss: 4.672011, 23712.000000/59000.000000
loss: 4.671840, 24352.000000/59000.000000
loss: 4.670897, 24992.000000/59000.000000
loss: 4.671302, 25632.000000/59000.000000
loss: 4.671803, 26272.000000/59000.000000
loss: 4.683071, 26912.000000/59000.000000
loss: 4.684633, 27552.000000/59000.000000
loss: 4.686196, 28192.000000/59000.000000
loss: 4.688540, 28832.000000/59000.000000
loss: 4.686196, 29472.000000/59000.000000
loss: 4.683852, 30112.000000/59000.000000
loss: 4.683852, 30752.000000/59000.000000
loss: 4.686977, 31392.000000/59000.000000
loss: 4.686196, 32032.000000/59000.000000
loss: 4.685414, 32672.000000/59000.000000
loss: 4.686196, 33312.000000/59000.000000
loss: 4.683071, 33952.000000/59000.000000
loss: 4.683071, 34592.000000/59000.000000
loss: 4.679946, 35232.000000/59000.000000
loss: 4.683071, 35872.000000/59000.000000
loss: 4.682290, 36512.000000/59000.000000
loss: 4.681508, 37152.000000/59000.000000
loss: 4.687758, 37792.000000/59000.000000
loss: 4.688540, 38432.000000/59000.000000
loss: 4.684633, 39072.000000/59000.000000
loss: 4.683071, 39712.000000/59000.000000
loss: 4.683852, 40352.000000/59000.000000
loss: 4.689321, 40992.000000/59000.000000
loss: 4.684633, 41632.000000/59000.000000
loss: 4.697133, 42272.000000/59000.000000
loss: 4.694008, 42912.000000/59000.000000
loss: 4.697133, 43552.000000/59000.000000
loss: 4.695571, 44192.000000/59000.000000
loss: 4.695571, 44832.000000/59000.000000
loss: 4.697133, 45472.000000/59000.000000
loss: 4.695571, 46112.000000/59000.000000
loss: 4.696352, 46752.000000/59000.000000
loss: 4.697133, 47392.000000/59000.000000
loss: 4.697915, 48032.000000/59000.000000
loss: 4.695571, 48672.000000/59000.000000
loss: 4.697133, 49312.000000/59000.000000
loss: 4.696352, 49952.000000/59000.000000
loss: 4.697133, 50592.000000/59000.000000
loss: 4.696352, 51232.000000/59000.000000
loss: 4.695571, 51872.000000/59000.000000
loss: 4.694789, 52512.000000/59000.000000
loss: 4.697915, 53152.000000/59000.000000
loss: 4.695571, 53792.000000/59000.000000
loss: 4.684633, 54432.000000/59000.000000
loss: 4.692446, 55072.000000/59000.000000
loss: 4.681508, 55712.000000/59000.000000
loss: 4.685414, 56352.000000/59000.000000
loss: 4.687758, 56992.000000/59000.000000
loss: 4.692446, 57632.000000/59000.000000
loss: 4.686977, 58272.000000/59000.000000
loss: 4.686977, 58912.000000/59000.000000
tensor([[96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96],
        [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,
         96, 96, 96, 96]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.685585 

Done!
Epoch 2

loss: 4.688540, 32.000000/59000.000000
loss: 4.686977, 672.000000/59000.000000
loss: 4.686977, 1312.000000/59000.000000
loss: 4.686977, 1952.000000/59000.000000
loss: 4.679164, 2592.000000/59000.000000
loss: 4.686196, 3232.000000/59000.000000
loss: 4.684633, 3872.000000/59000.000000
loss: 4.681508, 4512.000000/59000.000000
loss: 4.678383, 5152.000000/59000.000000
loss: 4.687758, 5792.000000/59000.000000
loss: 4.685414, 6432.000000/59000.000000
loss: 4.688540, 7072.000000/59000.000000
loss: 4.686977, 7712.000000/59000.000000
loss: 4.684633, 8352.000000/59000.000000
loss: 4.691665, 8992.000000/59000.000000
loss: 4.683071, 9632.000000/59000.000000
loss: 4.683852, 10272.000000/59000.000000
loss: 4.687758, 10912.000000/59000.000000
loss: 4.681508, 11552.000000/59000.000000
loss: 4.686196, 12192.000000/59000.000000
loss: 4.690883, 12832.000000/59000.000000
loss: 4.686977, 13472.000000/59000.000000
loss: 4.688540, 14112.000000/59000.000000
loss: 4.676821, 14752.000000/59000.000000
loss: 4.690102, 15392.000000/59000.000000
loss: 4.683852, 16032.000000/59000.000000
loss: 4.681508, 16672.000000/59000.000000
loss: 4.686196, 17312.000000/59000.000000
loss: 4.683852, 17952.000000/59000.000000
loss: 4.686196, 18592.000000/59000.000000
loss: 4.690102, 19232.000000/59000.000000
loss: 4.685414, 19872.000000/59000.000000
loss: 4.686977, 20512.000000/59000.000000
loss: 4.682290, 21152.000000/59000.000000
loss: 4.684633, 21792.000000/59000.000000
loss: 4.685414, 22432.000000/59000.000000
loss: 4.689321, 23072.000000/59000.000000
loss: 4.686196, 23712.000000/59000.000000
loss: 4.686977, 24352.000000/59000.000000
loss: 4.683071, 24992.000000/59000.000000
loss: 4.683852, 25632.000000/59000.000000
loss: 4.686196, 26272.000000/59000.000000
loss: 4.673198, 26912.000000/59000.000000
loss: 4.672133, 27552.000000/59000.000000
loss: 4.672879, 28192.000000/59000.000000
loss: 4.672757, 28832.000000/59000.000000
loss: 4.671717, 29472.000000/59000.000000
loss: 4.671643, 30112.000000/59000.000000
loss: 4.672120, 30752.000000/59000.000000
loss: 4.673197, 31392.000000/59000.000000
loss: 4.671998, 32032.000000/59000.000000
loss: 4.672230, 32672.000000/59000.000000
loss: 4.672683, 33312.000000/59000.000000
loss: 4.672549, 33952.000000/59000.000000
loss: 4.672121, 34592.000000/59000.000000
loss: 4.673258, 35232.000000/59000.000000
loss: 4.671729, 35872.000000/59000.000000
loss: 4.686977, 36512.000000/59000.000000
loss: 4.690102, 37152.000000/59000.000000
loss: 4.684633, 37792.000000/59000.000000
loss: 4.687758, 38432.000000/59000.000000
loss: 4.688540, 39072.000000/59000.000000
loss: 4.685414, 39712.000000/59000.000000
loss: 4.678383, 40352.000000/59000.000000
loss: 4.687758, 40992.000000/59000.000000
loss: 4.690883, 41632.000000/59000.000000
loss: 4.685414, 42272.000000/59000.000000
loss: 4.682290, 42912.000000/59000.000000
loss: 4.685414, 43552.000000/59000.000000
loss: 4.684633, 44192.000000/59000.000000
loss: 4.685414, 44832.000000/59000.000000
loss: 4.696352, 45472.000000/59000.000000
loss: 4.695571, 46112.000000/59000.000000
loss: 4.694008, 46752.000000/59000.000000
loss: 4.697133, 47392.000000/59000.000000
loss: 4.697133, 48032.000000/59000.000000
loss: 4.696352, 48672.000000/59000.000000
loss: 4.697133, 49312.000000/59000.000000
loss: 4.697915, 49952.000000/59000.000000
loss: 4.697133, 50592.000000/59000.000000
loss: 4.695571, 51232.000000/59000.000000
loss: 4.697133, 51872.000000/59000.000000
loss: 4.694789, 52512.000000/59000.000000
loss: 4.697915, 53152.000000/59000.000000
loss: 4.697133, 53792.000000/59000.000000
loss: 4.697133, 54432.000000/59000.000000
loss: 4.695571, 55072.000000/59000.000000
loss: 4.696352, 55712.000000/59000.000000
loss: 4.697130, 56352.000000/59000.000000
loss: 4.696352, 56992.000000/59000.000000
loss: 4.695571, 57632.000000/59000.000000
loss: 4.696352, 58272.000000/59000.000000
loss: 4.696352, 58912.000000/59000.000000
tensor([[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20],
        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
         20, 20, 20, 20]])
Test Error: 
 Accuracy: 0.1%, Avg loss: 4.696547 

Done!
Epoch 3

loss: 4.694789, 32.000000/59000.000000
loss: 4.696352, 672.000000/59000.000000
loss: 4.693227, 1312.000000/59000.000000
loss: 4.697133, 1952.000000/59000.000000
loss: 4.697915, 2592.000000/59000.000000
loss: 4.696352, 3232.000000/59000.000000
loss: 4.694789, 3872.000000/59000.000000
loss: 4.697133, 4512.000000/59000.000000
loss: 4.697133, 5152.000000/59000.000000
loss: 4.696352, 5792.000000/59000.000000
loss: 4.694008, 6432.000000/59000.000000
loss: 4.696352, 7072.000000/59000.000000
loss: 4.697133, 7712.000000/59000.000000
loss: 4.697915, 8352.000000/59000.000000
loss: 4.696352, 8992.000000/59000.000000
loss: 4.696352, 9632.000000/59000.000000
loss: 4.695571, 10272.000000/59000.000000
loss: 4.695571, 10912.000000/59000.000000
loss: 4.697915, 11552.000000/59000.000000
loss: 4.694789, 12192.000000/59000.000000
loss: 4.697133, 12832.000000/59000.000000
loss: 4.697133, 13472.000000/59000.000000
loss: 4.697133, 14112.000000/59000.000000
loss: 4.697915, 14752.000000/59000.000000
loss: 4.697133, 15392.000000/59000.000000
loss: 4.695571, 16032.000000/59000.000000
loss: 4.697133, 16672.000000/59000.000000
loss: 4.695571, 17312.000000/59000.000000
loss: 4.695571, 17952.000000/59000.000000
loss: 4.696352, 18592.000000/59000.000000
loss: 4.695571, 19232.000000/59000.000000
loss: 4.695571, 19872.000000/59000.000000
loss: 4.696352, 20512.000000/59000.000000
loss: 4.696352, 21152.000000/59000.000000
loss: 4.696352, 21792.000000/59000.000000
loss: 4.696352, 22432.000000/59000.000000
loss: 4.697133, 23072.000000/59000.000000
loss: 4.695571, 23712.000000/59000.000000
loss: 4.695571, 24352.000000/59000.000000
loss: 4.696352, 24992.000000/59000.000000
loss: 4.697133, 25632.000000/59000.000000
loss: 4.697133, 26272.000000/59000.000000
loss: 4.694789, 26912.000000/59000.000000
loss: 4.695571, 27552.000000/59000.000000
loss: 4.696352, 28192.000000/59000.000000
loss: 4.697915, 28832.000000/59000.000000
loss: 4.694789, 29472.000000/59000.000000
loss: 4.697915, 30112.000000/59000.000000
loss: 4.697133, 30752.000000/59000.000000
loss: 4.695571, 31392.000000/59000.000000
loss: 4.694789, 32032.000000/59000.000000
loss: 4.697915, 32672.000000/59000.000000
loss: 4.696352, 33312.000000/59000.000000
loss: 4.697133, 33952.000000/59000.000000
loss: 4.697915, 34592.000000/59000.000000
loss: 4.694008, 35232.000000/59000.000000
loss: 4.696352, 35872.000000/59000.000000
loss: 4.697915, 36512.000000/59000.000000
loss: 4.697133, 37152.000000/59000.000000
loss: 4.697133, 37792.000000/59000.000000
loss: 4.695571, 38432.000000/59000.000000
loss: 4.697133, 39072.000000/59000.000000
loss: 4.697915, 39712.000000/59000.000000
loss: 4.697133, 40352.000000/59000.000000
loss: 4.697133, 40992.000000/59000.000000
loss: 4.696352, 41632.000000/59000.000000
loss: 4.695571, 42272.000000/59000.000000
loss: 4.697915, 42912.000000/59000.000000
loss: 4.697915, 43552.000000/59000.000000
loss: 4.697133, 44192.000000/59000.000000
loss: 4.696352, 44832.000000/59000.000000
loss: 4.696352, 45472.000000/59000.000000
loss: 4.695571, 46112.000000/59000.000000
loss: 4.697915, 46752.000000/59000.000000
loss: 4.697133, 47392.000000/59000.000000
loss: 4.697133, 48032.000000/59000.000000
loss: 4.697133, 48672.000000/59000.000000
loss: 4.697133, 49312.000000/59000.000000
loss: 4.697133, 49952.000000/59000.000000
loss: 4.697133, 50592.000000/59000.000000
loss: 4.696352, 51232.000000/59000.000000
loss: 4.694789, 51872.000000/59000.000000
loss: 4.696352, 52512.000000/59000.000000
loss: 4.696352, 53152.000000/59000.000000
loss: 4.695571, 53792.000000/59000.000000
loss: 4.697133, 54432.000000/59000.000000
loss: 4.695571, 55072.000000/59000.000000
loss: 4.696352, 55712.000000/59000.000000
loss: 4.695571, 56352.000000/59000.000000
loss: 4.697133, 56992.000000/59000.000000
loss: 4.695571, 57632.000000/59000.000000
loss: 4.697133, 58272.000000/59000.000000
loss: 4.695571, 58912.000000/59000.000000
tensor([[99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49],
        [99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49, 99, 49,
         99, 49, 99, 49]])
Test Error: 
 Accuracy: 0.2%, Avg loss: 4.696181 

Done!
Epoch 4

loss: 4.697133, 32.000000/59000.000000
loss: 4.695571, 672.000000/59000.000000
loss: 4.689321, 1312.000000/59000.000000
loss: 4.690883, 1952.000000/59000.000000
loss: 4.688540, 2592.000000/59000.000000
loss: 4.692446, 3232.000000/59000.000000
loss: 4.691665, 3872.000000/59000.000000
loss: 4.688540, 4512.000000/59000.000000
loss: 4.686977, 5152.000000/59000.000000
loss: 4.693227, 5792.000000/59000.000000
loss: 4.691665, 6432.000000/59000.000000
loss: 4.691665, 7072.000000/59000.000000
loss: 4.690102, 7712.000000/59000.000000
loss: 4.691665, 8352.000000/59000.000000
loss: 4.690102, 8992.000000/59000.000000
loss: 4.686977, 9632.000000/59000.000000
loss: 4.679946, 10272.000000/59000.000000
loss: 4.683071, 10912.000000/59000.000000
loss: 4.680727, 11552.000000/59000.000000
loss: 4.676821, 12192.000000/59000.000000
loss: 4.688540, 12832.000000/59000.000000
loss: 4.681508, 13472.000000/59000.000000
loss: 4.684633, 14112.000000/59000.000000
loss: 4.684633, 14752.000000/59000.000000
loss: 4.691665, 15392.000000/59000.000000
loss: 4.677602, 16032.000000/59000.000000
loss: 4.683071, 16672.000000/59000.000000
loss: 4.685414, 17312.000000/59000.000000
loss: 4.683852, 17952.000000/59000.000000
loss: 4.688540, 18592.000000/59000.000000
loss: 4.684633, 19232.000000/59000.000000
loss: 4.686196, 19872.000000/59000.000000
loss: 4.688540, 20512.000000/59000.000000
loss: 4.693227, 21152.000000/59000.000000
loss: 4.692446, 21792.000000/59000.000000
loss: 4.693227, 22432.000000/59000.000000
loss: 4.695571, 23072.000000/59000.000000
loss: 4.696352, 23712.000000/59000.000000
loss: 4.695571, 24352.000000/59000.000000
loss: 4.694008, 24992.000000/59000.000000
loss: 4.695571, 25632.000000/59000.000000
loss: 4.693227, 26272.000000/59000.000000
loss: 4.695571, 26912.000000/59000.000000
loss: 4.695571, 27552.000000/59000.000000
loss: 4.694008, 28192.000000/59000.000000
loss: 4.693227, 28832.000000/59000.000000
loss: 4.694789, 29472.000000/59000.000000
loss: 4.695571, 30112.000000/59000.000000
loss: 4.693227, 30752.000000/59000.000000
loss: 4.692446, 31392.000000/59000.000000
loss: 4.697915, 32032.000000/59000.000000
loss: 4.696352, 32672.000000/59000.000000
loss: 4.691665, 33312.000000/59000.000000
loss: 4.688540, 33952.000000/59000.000000
loss: 4.686977, 34592.000000/59000.000000
loss: 4.689321, 35232.000000/59000.000000
loss: 4.697915, 35872.000000/59000.000000
loss: 4.689321, 36512.000000/59000.000000
loss: 4.687758, 37152.000000/59000.000000
loss: 4.682290, 37792.000000/59000.000000
loss: 4.690102, 38432.000000/59000.000000
loss: 4.688540, 39072.000000/59000.000000
loss: 4.682290, 39712.000000/59000.000000
loss: 4.690883, 40352.000000/59000.000000
loss: 4.683852, 40992.000000/59000.000000
loss: 4.684633, 41632.000000/59000.000000
loss: 4.687758, 42272.000000/59000.000000
loss: 4.684633, 42912.000000/59000.000000
loss: 4.689321, 43552.000000/59000.000000
loss: 4.686196, 44192.000000/59000.000000
loss: 4.683071, 44832.000000/59000.000000
loss: 4.680727, 45472.000000/59000.000000
loss: 4.690883, 46112.000000/59000.000000
loss: 4.687758, 46752.000000/59000.000000
loss: 4.685414, 47392.000000/59000.000000
loss: 4.683852, 48032.000000/59000.000000
loss: 4.690102, 48672.000000/59000.000000
loss: 4.686196, 49312.000000/59000.000000
loss: 4.681508, 49952.000000/59000.000000
loss: 4.687758, 50592.000000/59000.000000
loss: 4.686977, 51232.000000/59000.000000
loss: 4.687758, 51872.000000/59000.000000
loss: 4.685414, 52512.000000/59000.000000
loss: 4.687758, 53152.000000/59000.000000
loss: 4.683071, 53792.000000/59000.000000
loss: 4.687758, 54432.000000/59000.000000
loss: 4.683071, 55072.000000/59000.000000
loss: 4.685414, 55712.000000/59000.000000
loss: 4.684633, 56352.000000/59000.000000
loss: 4.683852, 56992.000000/59000.000000
loss: 4.697133, 57632.000000/59000.000000
loss: 4.697915, 58272.000000/59000.000000
loss: 4.696352, 58912.000000/59000.000000
tensor([[ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37],
        [ 8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,  8, 37,
          8, 37,  8, 37]])
Test Error: 
 Accuracy: 0.1%, Avg loss: 4.696328 

Done!
Epoch 5

loss: 4.696352, 32.000000/59000.000000
loss: 4.696352, 672.000000/59000.000000
loss: 4.697133, 1312.000000/59000.000000
loss: 4.697915, 1952.000000/59000.000000
loss: 4.696352, 2592.000000/59000.000000
loss: 4.695571, 3232.000000/59000.000000
loss: 4.697133, 3872.000000/59000.000000
loss: 4.696352, 4512.000000/59000.000000
loss: 4.697133, 5152.000000/59000.000000
loss: 4.697915, 5792.000000/59000.000000
loss: 4.697915, 6432.000000/59000.000000
loss: 4.696352, 7072.000000/59000.000000
loss: 4.695571, 7712.000000/59000.000000
loss: 4.695571, 8352.000000/59000.000000
loss: 4.697133, 8992.000000/59000.000000
loss: 4.693227, 9632.000000/59000.000000
loss: 4.695571, 10272.000000/59000.000000
loss: 4.696352, 10912.000000/59000.000000
loss: 4.696352, 11552.000000/59000.000000
loss: 4.697915, 12192.000000/59000.000000
loss: 4.696352, 12832.000000/59000.000000
loss: 4.696352, 13472.000000/59000.000000
loss: 4.692446, 14112.000000/59000.000000
loss: 4.697915, 14752.000000/59000.000000
loss: 4.697133, 15392.000000/59000.000000
loss: 4.697133, 16032.000000/59000.000000
loss: 4.697133, 16672.000000/59000.000000
loss: 4.697915, 17312.000000/59000.000000
loss: 4.695571, 17952.000000/59000.000000
loss: 4.694008, 18592.000000/59000.000000
loss: 4.697915, 19232.000000/59000.000000
loss: 4.697133, 19872.000000/59000.000000
loss: 4.697133, 20512.000000/59000.000000
loss: 4.697133, 21152.000000/59000.000000
loss: 4.697915, 21792.000000/59000.000000
loss: 4.696352, 22432.000000/59000.000000
loss: 4.697915, 23072.000000/59000.000000
loss: 4.697133, 23712.000000/59000.000000
loss: 4.697915, 24352.000000/59000.000000
loss: 4.695571, 24992.000000/59000.000000
loss: 4.695571, 25632.000000/59000.000000
loss: 4.696352, 26272.000000/59000.000000
loss: 4.695571, 26912.000000/59000.000000
loss: 4.697133, 27552.000000/59000.000000
loss: 4.697133, 28192.000000/59000.000000
loss: 4.697133, 28832.000000/59000.000000
loss: 4.694789, 29472.000000/59000.000000
loss: 4.697915, 30112.000000/59000.000000
loss: 4.697915, 30752.000000/59000.000000
loss: 4.697915, 31392.000000/59000.000000
loss: 4.697133, 32032.000000/59000.000000
loss: 4.697133, 32672.000000/59000.000000
loss: 4.697133, 33312.000000/59000.000000
loss: 4.697133, 33952.000000/59000.000000
loss: 4.696352, 34592.000000/59000.000000
loss: 4.696352, 35232.000000/59000.000000
loss: 4.697915, 35872.000000/59000.000000
loss: 4.696352, 36512.000000/59000.000000
loss: 4.695571, 37152.000000/59000.000000
loss: 4.695571, 37792.000000/59000.000000
loss: 4.697133, 38432.000000/59000.000000
loss: 4.697133, 39072.000000/59000.000000
loss: 4.696352, 39712.000000/59000.000000
loss: 4.697915, 40352.000000/59000.000000
loss: 4.697133, 40992.000000/59000.000000
loss: 4.695571, 41632.000000/59000.000000
loss: 4.697133, 42272.000000/59000.000000
loss: 4.696352, 42912.000000/59000.000000
loss: 4.694789, 43552.000000/59000.000000
loss: 4.694789, 44192.000000/59000.000000
loss: 4.697133, 44832.000000/59000.000000
loss: 4.696352, 45472.000000/59000.000000
loss: 4.694789, 46112.000000/59000.000000
loss: 4.696352, 46752.000000/59000.000000
loss: 4.694789, 47392.000000/59000.000000
loss: 4.695571, 48032.000000/59000.000000
loss: 4.695571, 48672.000000/59000.000000
loss: 4.697915, 49312.000000/59000.000000
loss: 4.697915, 49952.000000/59000.000000
loss: 4.697133, 50592.000000/59000.000000
loss: 4.696352, 51232.000000/59000.000000
loss: 4.690883, 51872.000000/59000.000000
loss: 4.693227, 52512.000000/59000.000000
loss: 4.695571, 53152.000000/59000.000000
loss: 4.696352, 53792.000000/59000.000000
loss: 4.697133, 54432.000000/59000.000000
loss: 4.697133, 55072.000000/59000.000000
loss: 4.696352, 55712.000000/59000.000000
loss: 4.697133, 56352.000000/59000.000000
loss: 4.697133, 56992.000000/59000.000000
loss: 4.697133, 57632.000000/59000.000000
loss: 4.697133, 58272.000000/59000.000000
loss: 4.697133, 58912.000000/59000.000000
tensor([[73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75],
        [73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75, 73, 75,
         73, 75, 73, 75]])
Test Error: 
 Accuracy: 0.1%, Avg loss: 4.696474 


continued with SGD

Epoch 1

loss: 4.683071, 32.000000/59000.000000
loss: 4.683852, 672.000000/59000.000000
loss: 4.687758, 1312.000000/59000.000000
loss: 4.686977, 1952.000000/59000.000000
loss: 4.679164, 2592.000000/59000.000000
loss: 4.682290, 3232.000000/59000.000000
loss: 4.688540, 3872.000000/59000.000000
loss: 4.686977, 4512.000000/59000.000000
loss: 4.686196, 5152.000000/59000.000000
loss: 4.681508, 5792.000000/59000.000000
loss: 4.687758, 6432.000000/59000.000000
loss: 4.686977, 7072.000000/59000.000000
loss: 4.681508, 7712.000000/59000.000000
loss: 4.686196, 8352.000000/59000.000000
loss: 4.687758, 8992.000000/59000.000000
loss: 4.686196, 9632.000000/59000.000000
loss: 4.678383, 10272.000000/59000.000000
loss: 4.690102, 10912.000000/59000.000000
loss: 4.689321, 11552.000000/59000.000000
loss: 4.680727, 12192.000000/59000.000000
loss: 4.686977, 12832.000000/59000.000000
loss: 4.689321, 13472.000000/59000.000000
loss: 4.686196, 14112.000000/59000.000000
loss: 4.681508, 14752.000000/59000.000000
loss: 4.679946, 15392.000000/59000.000000
loss: 4.681508, 16032.000000/59000.000000
loss: 4.687758, 16672.000000/59000.000000
loss: 4.683852, 17312.000000/59000.000000
loss: 4.686977, 17952.000000/59000.000000
loss: 4.683071, 18592.000000/59000.000000
loss: 4.684633, 19232.000000/59000.000000
loss: 4.686977, 19872.000000/59000.000000
loss: 4.685414, 20512.000000/59000.000000
loss: 4.679946, 21152.000000/59000.000000
loss: 4.688540, 21792.000000/59000.000000
loss: 4.684633, 22432.000000/59000.000000
loss: 4.686977, 23072.000000/59000.000000
loss: 4.683071, 23712.000000/59000.000000
loss: 4.685414, 24352.000000/59000.000000
loss: 4.686977, 24992.000000/59000.000000
loss: 4.694008, 25632.000000/59000.000000
loss: 4.684633, 26272.000000/59000.000000
loss: 4.683852, 26912.000000/59000.000000
loss: 4.682290, 27552.000000/59000.000000
loss: 4.682290, 28192.000000/59000.000000
loss: 4.688540, 28832.000000/59000.000000
loss: 4.686977, 29472.000000/59000.000000
loss: 4.689321, 30112.000000/59000.000000
loss: 4.679164, 30752.000000/59000.000000
loss: 4.683071, 31392.000000/59000.000000
loss: 4.684633, 32032.000000/59000.000000
loss: 4.688540, 32672.000000/59000.000000
loss: 4.683071, 33312.000000/59000.000000
loss: 4.685414, 33952.000000/59000.000000
loss: 4.683071, 34592.000000/59000.000000
loss: 4.685414, 35232.000000/59000.000000
loss: 4.688540, 35872.000000/59000.000000
loss: 4.686196, 36512.000000/59000.000000
loss: 4.684633, 37152.000000/59000.000000
loss: 4.684633, 37792.000000/59000.000000
loss: 4.686977, 38432.000000/59000.000000
loss: 4.682290, 39072.000000/59000.000000
loss: 4.686196, 39712.000000/59000.000000
loss: 4.688540, 40352.000000/59000.000000
loss: 4.684633, 40992.000000/59000.000000
loss: 4.684633, 41632.000000/59000.000000
loss: 4.685414, 42272.000000/59000.000000
loss: 4.679164, 42912.000000/59000.000000
loss: 4.683071, 43552.000000/59000.000000
loss: 4.689321, 44192.000000/59000.000000
loss: 4.686977, 44832.000000/59000.000000
loss: 4.683071, 45472.000000/59000.000000
loss: 4.688540, 46112.000000/59000.000000
loss: 4.685414, 46752.000000/59000.000000
loss: 4.686196, 47392.000000/59000.000000
loss: 4.684633, 48032.000000/59000.000000
loss: 4.687758, 48672.000000/59000.000000
loss: 4.686196, 49312.000000/59000.000000
loss: 4.680727, 49952.000000/59000.000000
loss: 4.689321, 50592.000000/59000.000000
loss: 4.688540, 51232.000000/59000.000000
loss: 4.681508, 51872.000000/59000.000000
loss: 4.686196, 52512.000000/59000.000000
loss: 4.688540, 53152.000000/59000.000000
loss: 4.682290, 53792.000000/59000.000000
loss: 4.683852, 54432.000000/59000.000000
loss: 4.686196, 55072.000000/59000.000000
loss: 4.690102, 55712.000000/59000.000000
loss: 4.689321, 56352.000000/59000.000000
loss: 4.685414, 56992.000000/59000.000000
loss: 4.677602, 57632.000000/59000.000000
loss: 4.685414, 58272.000000/59000.000000
loss: 4.683071, 58912.000000/59000.000000
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  23,  98,  ..., 107, 107, 107],
        [103,  93, 103,  ..., 107, 107, 107],
        [ 93,  35,  95,  ..., 107, 107, 107],
        ...,
        [103,  48, 106,  ..., 107, 107, 107],
        [ 93,  23,  95,  ..., 107, 107, 107],
        [ 31,  95,  85,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  93,  89,  ..., 107, 107, 107],
        [ 91, 106,  77,  ..., 107, 107, 107],
        [ 93,  61,  96,  ..., 107, 107, 107],
        ...,
        [103,  93,  66,  ..., 107, 107, 107],
        [103,  93,  93,  ..., 107, 107, 107],
        [ 93,  74, 106,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  93, 103,  ..., 107, 107, 107],
        [ 89,  26, 105,  ..., 107, 107, 107],
        [101,  93,   5,  ..., 107, 107, 107],
        ...,
        [101, 103,  20,  ..., 107, 107, 107],
        [ 54,  96,  33,  ..., 107, 107, 107],
        [103,  93,  31,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  11,  96,  ..., 107, 107, 107],
        [103,  93,  78,  ..., 107, 107, 107],
        [103, 101,  93,  ..., 107, 107, 107],
        ...,
        [101,  18,  89,  ..., 107, 107, 107],
        [103, 101,   8,  ..., 107, 107, 107],
        [ 99, 101,  19,  ..., 107, 107, 107]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.686098 

Epoch 2

loss: 4.691665, 32.000000/59000.000000
loss: 4.689321, 672.000000/59000.000000
loss: 4.690883, 1312.000000/59000.000000
loss: 4.680727, 1952.000000/59000.000000
loss: 4.685414, 2592.000000/59000.000000
loss: 4.682290, 3232.000000/59000.000000
loss: 4.686196, 3872.000000/59000.000000
loss: 4.680727, 4512.000000/59000.000000
loss: 4.683852, 5152.000000/59000.000000
loss: 4.684633, 5792.000000/59000.000000
loss: 4.689321, 6432.000000/59000.000000
loss: 4.690883, 7072.000000/59000.000000
loss: 4.684633, 7712.000000/59000.000000
loss: 4.689321, 8352.000000/59000.000000
loss: 4.690102, 8992.000000/59000.000000
loss: 4.688540, 9632.000000/59000.000000
loss: 4.681508, 10272.000000/59000.000000
loss: 4.687758, 10912.000000/59000.000000
loss: 4.683071, 11552.000000/59000.000000
loss: 4.685414, 12192.000000/59000.000000
loss: 4.685414, 12832.000000/59000.000000
loss: 4.683852, 13472.000000/59000.000000
loss: 4.683852, 14112.000000/59000.000000
loss: 4.682290, 14752.000000/59000.000000
loss: 4.690102, 15392.000000/59000.000000
loss: 4.679164, 16032.000000/59000.000000
loss: 4.687758, 16672.000000/59000.000000
loss: 4.694008, 17312.000000/59000.000000
loss: 4.683852, 17952.000000/59000.000000
loss: 4.687758, 18592.000000/59000.000000
loss: 4.682290, 19232.000000/59000.000000
loss: 4.686196, 19872.000000/59000.000000
loss: 4.685414, 20512.000000/59000.000000
loss: 4.678383, 21152.000000/59000.000000
loss: 4.682290, 21792.000000/59000.000000
loss: 4.686196, 22432.000000/59000.000000
loss: 4.683852, 23072.000000/59000.000000
loss: 4.684633, 23712.000000/59000.000000
loss: 4.681508, 24352.000000/59000.000000
loss: 4.685414, 24992.000000/59000.000000
loss: 4.683071, 25632.000000/59000.000000
loss: 4.682290, 26272.000000/59000.000000
loss: 4.684633, 26912.000000/59000.000000
loss: 4.683852, 27552.000000/59000.000000
loss: 4.684633, 28192.000000/59000.000000
loss: 4.686196, 28832.000000/59000.000000
loss: 4.687758, 29472.000000/59000.000000
loss: 4.683852, 30112.000000/59000.000000
loss: 4.686196, 30752.000000/59000.000000
loss: 4.686196, 31392.000000/59000.000000
loss: 4.686196, 32032.000000/59000.000000
loss: 4.685414, 32672.000000/59000.000000
loss: 4.686977, 33312.000000/59000.000000
loss: 4.691665, 33952.000000/59000.000000
loss: 4.683071, 34592.000000/59000.000000
loss: 4.681508, 35232.000000/59000.000000
loss: 4.685414, 35872.000000/59000.000000
loss: 4.687758, 36512.000000/59000.000000
loss: 4.688540, 37152.000000/59000.000000
loss: 4.688540, 37792.000000/59000.000000
loss: 4.686977, 38432.000000/59000.000000
loss: 4.683071, 39072.000000/59000.000000
loss: 4.681508, 39712.000000/59000.000000
loss: 4.685414, 40352.000000/59000.000000
loss: 4.686977, 40992.000000/59000.000000
loss: 4.684633, 41632.000000/59000.000000
loss: 4.683071, 42272.000000/59000.000000
loss: 4.684633, 42912.000000/59000.000000
loss: 4.683071, 43552.000000/59000.000000
loss: 4.681508, 44192.000000/59000.000000
loss: 4.690102, 44832.000000/59000.000000
loss: 4.686196, 45472.000000/59000.000000
loss: 4.680727, 46112.000000/59000.000000
loss: 4.685414, 46752.000000/59000.000000
loss: 4.684633, 47392.000000/59000.000000
loss: 4.686977, 48032.000000/59000.000000
loss: 4.680727, 48672.000000/59000.000000
loss: 4.687758, 49312.000000/59000.000000
loss: 4.686977, 49952.000000/59000.000000
loss: 4.686977, 50592.000000/59000.000000
loss: 4.688540, 51232.000000/59000.000000
loss: 4.686977, 51872.000000/59000.000000
loss: 4.685414, 52512.000000/59000.000000
loss: 4.688540, 53152.000000/59000.000000
loss: 4.685414, 53792.000000/59000.000000
loss: 4.685414, 54432.000000/59000.000000
loss: 4.686977, 55072.000000/59000.000000
loss: 4.680727, 55712.000000/59000.000000
loss: 4.686977, 56352.000000/59000.000000
loss: 4.686196, 56992.000000/59000.000000
loss: 4.680727, 57632.000000/59000.000000
loss: 4.688540, 58272.000000/59000.000000
loss: 4.684633, 58912.000000/59000.000000
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  23,  98,  ..., 107, 107, 107],
        [103,  93, 103,  ..., 107, 107, 107],
        [ 93,  35,  95,  ..., 107, 107, 107],
        ...,
        [103,  48, 106,  ..., 107, 107, 107],
        [ 93,  23,  95,  ..., 107, 107, 107],
        [ 31,  95,  85,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  93,  89,  ..., 107, 107, 107],
        [ 91, 106,  77,  ..., 107, 107, 107],
        [ 93,  61,  96,  ..., 107, 107, 107],
        ...,
        [103,  93,  66,  ..., 107, 107, 107],
        [103,  93,  93,  ..., 107, 107, 107],
        [ 93,  74, 106,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  93, 103,  ..., 107, 107, 107],
        [ 89,  26, 105,  ..., 107, 107, 107],
        [101,  93,   5,  ..., 107, 107, 107],
        ...,
        [101, 103,  20,  ..., 107, 107, 107],
        [ 54,  96,  33,  ..., 107, 107, 107],
        [103,  93,  31,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  11,  96,  ..., 107, 107, 107],
        [103,  93,  78,  ..., 107, 107, 107],
        [103, 101,  93,  ..., 107, 107, 107],
        ...,
        [101,  18,  89,  ..., 107, 107, 107],
        [103, 101,   8,  ..., 107, 107, 107],
        [ 99, 101,  19,  ..., 107, 107, 107]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.686098 

Epoch 3

loss: 4.690102, 32.000000/59000.000000
loss: 4.683852, 672.000000/59000.000000
loss: 4.686196, 1312.000000/59000.000000
loss: 4.689321, 1952.000000/59000.000000
loss: 4.691665, 2592.000000/59000.000000
loss: 4.684633, 3232.000000/59000.000000
loss: 4.687758, 3872.000000/59000.000000
loss: 4.685414, 4512.000000/59000.000000
loss: 4.687758, 5152.000000/59000.000000
loss: 4.688540, 5792.000000/59000.000000
loss: 4.690883, 6432.000000/59000.000000
loss: 4.685414, 7072.000000/59000.000000
loss: 4.686977, 7712.000000/59000.000000
loss: 4.682290, 8352.000000/59000.000000
loss: 4.686196, 8992.000000/59000.000000
loss: 4.686977, 9632.000000/59000.000000
loss: 4.680727, 10272.000000/59000.000000
loss: 4.686977, 10912.000000/59000.000000
loss: 4.686196, 11552.000000/59000.000000
loss: 4.688540, 12192.000000/59000.000000
loss: 4.687758, 12832.000000/59000.000000
loss: 4.682290, 13472.000000/59000.000000
loss: 4.685414, 14112.000000/59000.000000
loss: 4.685414, 14752.000000/59000.000000
loss: 4.685414, 15392.000000/59000.000000
loss: 4.680727, 16032.000000/59000.000000
loss: 4.682290, 16672.000000/59000.000000
loss: 4.681508, 17312.000000/59000.000000
loss: 4.681508, 17952.000000/59000.000000
loss: 4.685414, 18592.000000/59000.000000
loss: 4.686196, 19232.000000/59000.000000
loss: 4.680727, 19872.000000/59000.000000
loss: 4.679946, 20512.000000/59000.000000
loss: 4.683852, 21152.000000/59000.000000
loss: 4.686196, 21792.000000/59000.000000
loss: 4.676821, 22432.000000/59000.000000
loss: 4.688540, 23072.000000/59000.000000
loss: 4.682290, 23712.000000/59000.000000
loss: 4.687758, 24352.000000/59000.000000
loss: 4.686196, 24992.000000/59000.000000
loss: 4.684633, 25632.000000/59000.000000
loss: 4.683852, 26272.000000/59000.000000
loss: 4.683852, 26912.000000/59000.000000
loss: 4.689321, 27552.000000/59000.000000
loss: 4.686196, 28192.000000/59000.000000
loss: 4.681508, 28832.000000/59000.000000
loss: 4.686977, 29472.000000/59000.000000
loss: 4.680727, 30112.000000/59000.000000
loss: 4.676821, 30752.000000/59000.000000
loss: 4.686977, 31392.000000/59000.000000
loss: 4.684633, 32032.000000/59000.000000
loss: 4.691665, 32672.000000/59000.000000
loss: 4.689321, 33312.000000/59000.000000
loss: 4.683852, 33952.000000/59000.000000
loss: 4.680727, 34592.000000/59000.000000
loss: 4.687758, 35232.000000/59000.000000
loss: 4.678383, 35872.000000/59000.000000
loss: 4.688540, 36512.000000/59000.000000
loss: 4.672133, 37152.000000/59000.000000
loss: 4.687758, 37792.000000/59000.000000
loss: 4.690883, 38432.000000/59000.000000
loss: 4.686977, 39072.000000/59000.000000
loss: 4.682290, 39712.000000/59000.000000
loss: 4.685414, 40352.000000/59000.000000
loss: 4.683852, 40992.000000/59000.000000
loss: 4.681508, 41632.000000/59000.000000
loss: 4.684633, 42272.000000/59000.000000
loss: 4.682290, 42912.000000/59000.000000
loss: 4.687758, 43552.000000/59000.000000
loss: 4.686977, 44192.000000/59000.000000
loss: 4.682290, 44832.000000/59000.000000
loss: 4.687758, 45472.000000/59000.000000
loss: 4.686196, 46112.000000/59000.000000
loss: 4.683852, 46752.000000/59000.000000
loss: 4.684633, 47392.000000/59000.000000
loss: 4.686196, 48032.000000/59000.000000
loss: 4.685414, 48672.000000/59000.000000
loss: 4.684633, 49312.000000/59000.000000
loss: 4.683852, 49952.000000/59000.000000
loss: 4.683852, 50592.000000/59000.000000
loss: 4.685414, 51232.000000/59000.000000
loss: 4.685414, 51872.000000/59000.000000
loss: 4.683071, 52512.000000/59000.000000
loss: 4.685414, 53152.000000/59000.000000
loss: 4.689321, 53792.000000/59000.000000
loss: 4.679946, 54432.000000/59000.000000
loss: 4.686977, 55072.000000/59000.000000
loss: 4.689321, 55712.000000/59000.000000
loss: 4.688540, 56352.000000/59000.000000
loss: 4.686977, 56992.000000/59000.000000
loss: 4.685414, 57632.000000/59000.000000
loss: 4.686977, 58272.000000/59000.000000
loss: 4.686977, 58912.000000/59000.000000
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  23,  98,  ..., 107, 107, 107],
        [103,  93, 103,  ..., 107, 107, 107],
        [ 93,  35,  95,  ..., 107, 107, 107],
        ...,
        [103,  48, 106,  ..., 107, 107, 107],
        [ 93,  23,  95,  ..., 107, 107, 107],
        [ 31,  95,  85,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  93,  89,  ..., 107, 107, 107],
        [ 91, 106,  77,  ..., 107, 107, 107],
        [ 93,  61,  96,  ..., 107, 107, 107],
        ...,
        [103,  93,  66,  ..., 107, 107, 107],
        [103,  93,  93,  ..., 107, 107, 107],
        [ 93,  74, 106,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  93, 103,  ..., 107, 107, 107],
        [ 89,  26, 105,  ..., 107, 107, 107],
        [101,  93,   5,  ..., 107, 107, 107],
        ...,
        [101, 103,  20,  ..., 107, 107, 107],
        [ 54,  96,  33,  ..., 107, 107, 107],
        [103,  93,  31,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  11,  96,  ..., 107, 107, 107],
        [103,  93,  78,  ..., 107, 107, 107],
        [103, 101,  93,  ..., 107, 107, 107],
        ...,
        [101,  18,  89,  ..., 107, 107, 107],
        [103, 101,   8,  ..., 107, 107, 107],
        [ 99, 101,  19,  ..., 107, 107, 107]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.686098 

Epoch 4

loss: 4.685414, 32.000000/59000.000000
loss: 4.685414, 672.000000/59000.000000
loss: 4.689321, 1312.000000/59000.000000
loss: 4.683852, 1952.000000/59000.000000
loss: 4.681508, 2592.000000/59000.000000
loss: 4.690102, 3232.000000/59000.000000
loss: 4.690883, 3872.000000/59000.000000
loss: 4.683852, 4512.000000/59000.000000
loss: 4.682290, 5152.000000/59000.000000
loss: 4.686196, 5792.000000/59000.000000
loss: 4.686977, 6432.000000/59000.000000
loss: 4.684633, 7072.000000/59000.000000
loss: 4.686977, 7712.000000/59000.000000
loss: 4.690102, 8352.000000/59000.000000
loss: 4.689321, 8992.000000/59000.000000
loss: 4.686196, 9632.000000/59000.000000
loss: 4.686977, 10272.000000/59000.000000
loss: 4.689321, 10912.000000/59000.000000
loss: 4.683852, 11552.000000/59000.000000
loss: 4.686196, 12192.000000/59000.000000
loss: 4.684633, 12832.000000/59000.000000
loss: 4.680727, 13472.000000/59000.000000
loss: 4.685414, 14112.000000/59000.000000
loss: 4.676821, 14752.000000/59000.000000
loss: 4.683071, 15392.000000/59000.000000
loss: 4.683071, 16032.000000/59000.000000
loss: 4.688540, 16672.000000/59000.000000
loss: 4.684633, 17312.000000/59000.000000
loss: 4.682290, 17952.000000/59000.000000
loss: 4.686977, 18592.000000/59000.000000
loss: 4.686977, 19232.000000/59000.000000
loss: 4.686977, 19872.000000/59000.000000
loss: 4.690102, 20512.000000/59000.000000
loss: 4.688540, 21152.000000/59000.000000
loss: 4.687758, 21792.000000/59000.000000
loss: 4.679946, 22432.000000/59000.000000
loss: 4.685414, 23072.000000/59000.000000
loss: 4.683852, 23712.000000/59000.000000
loss: 4.685414, 24352.000000/59000.000000
loss: 4.687758, 24992.000000/59000.000000
loss: 4.687758, 25632.000000/59000.000000
loss: 4.687758, 26272.000000/59000.000000
loss: 4.686977, 26912.000000/59000.000000
loss: 4.691665, 27552.000000/59000.000000
loss: 4.685414, 28192.000000/59000.000000
loss: 4.686977, 28832.000000/59000.000000
loss: 4.679946, 29472.000000/59000.000000
loss: 4.684633, 30112.000000/59000.000000
loss: 4.685414, 30752.000000/59000.000000
loss: 4.690883, 31392.000000/59000.000000
loss: 4.683852, 32032.000000/59000.000000
loss: 4.687758, 32672.000000/59000.000000
loss: 4.683852, 33312.000000/59000.000000
loss: 4.686977, 33952.000000/59000.000000
loss: 4.689321, 34592.000000/59000.000000
loss: 4.685414, 35232.000000/59000.000000
loss: 4.683071, 35872.000000/59000.000000
loss: 4.682290, 36512.000000/59000.000000
loss: 4.690102, 37152.000000/59000.000000
loss: 4.681508, 37792.000000/59000.000000
loss: 4.685414, 38432.000000/59000.000000
loss: 4.690102, 39072.000000/59000.000000
loss: 4.686196, 39712.000000/59000.000000
loss: 4.684633, 40352.000000/59000.000000
loss: 4.686196, 40992.000000/59000.000000
loss: 4.684633, 41632.000000/59000.000000
loss: 4.687758, 42272.000000/59000.000000
loss: 4.686977, 42912.000000/59000.000000
loss: 4.690102, 43552.000000/59000.000000
loss: 4.686196, 44192.000000/59000.000000
loss: 4.687758, 44832.000000/59000.000000
loss: 4.684633, 45472.000000/59000.000000
loss: 4.689321, 46112.000000/59000.000000
loss: 4.684633, 46752.000000/59000.000000
loss: 4.690883, 47392.000000/59000.000000
loss: 4.688540, 48032.000000/59000.000000
loss: 4.682290, 48672.000000/59000.000000
loss: 4.682290, 49312.000000/59000.000000
loss: 4.686977, 49952.000000/59000.000000
loss: 4.681508, 50592.000000/59000.000000
loss: 4.686977, 51232.000000/59000.000000
loss: 4.676821, 51872.000000/59000.000000
loss: 4.681508, 52512.000000/59000.000000
loss: 4.679946, 53152.000000/59000.000000
loss: 4.686977, 53792.000000/59000.000000
loss: 4.688540, 54432.000000/59000.000000
loss: 4.683071, 55072.000000/59000.000000
loss: 4.679164, 55712.000000/59000.000000
loss: 4.681508, 56352.000000/59000.000000
loss: 4.678383, 56992.000000/59000.000000
loss: 4.691665, 57632.000000/59000.000000
loss: 4.687758, 58272.000000/59000.000000
loss: 4.687758, 58912.000000/59000.000000
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  23,  98,  ..., 107, 107, 107],
        [103,  93, 103,  ..., 107, 107, 107],
        [ 93,  35,  95,  ..., 107, 107, 107],
        ...,
        [103,  48, 106,  ..., 107, 107, 107],
        [ 93,  23,  95,  ..., 107, 107, 107],
        [ 31,  95,  85,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  93,  89,  ..., 107, 107, 107],
        [ 91, 106,  77,  ..., 107, 107, 107],
        [ 93,  61,  96,  ..., 107, 107, 107],
        ...,
        [103,  93,  66,  ..., 107, 107, 107],
        [103,  93,  93,  ..., 107, 107, 107],
        [ 93,  74, 106,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  93, 103,  ..., 107, 107, 107],
        [ 89,  26, 105,  ..., 107, 107, 107],
        [101,  93,   5,  ..., 107, 107, 107],
        ...,
        [101, 103,  20,  ..., 107, 107, 107],
        [ 54,  96,  33,  ..., 107, 107, 107],
        [103,  93,  31,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  11,  96,  ..., 107, 107, 107],
        [103,  93,  78,  ..., 107, 107, 107],
        [103, 101,  93,  ..., 107, 107, 107],
        ...,
        [101,  18,  89,  ..., 107, 107, 107],
        [103, 101,   8,  ..., 107, 107, 107],
        [ 99, 101,  19,  ..., 107, 107, 107]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.686098 

Epoch 5

loss: 4.686977, 32.000000/59000.000000
loss: 4.683071, 672.000000/59000.000000
loss: 4.684633, 1312.000000/59000.000000
loss: 4.688540, 1952.000000/59000.000000
loss: 4.686977, 2592.000000/59000.000000
loss: 4.686196, 3232.000000/59000.000000
loss: 4.686977, 3872.000000/59000.000000
loss: 4.685414, 4512.000000/59000.000000
loss: 4.686977, 5152.000000/59000.000000
loss: 4.682290, 5792.000000/59000.000000
loss: 4.690883, 6432.000000/59000.000000
loss: 4.691665, 7072.000000/59000.000000
loss: 4.685414, 7712.000000/59000.000000
loss: 4.687758, 8352.000000/59000.000000
loss: 4.682290, 8992.000000/59000.000000
loss: 4.690102, 9632.000000/59000.000000
loss: 4.685414, 10272.000000/59000.000000
loss: 4.682290, 10912.000000/59000.000000
loss: 4.682290, 11552.000000/59000.000000
loss: 4.689321, 12192.000000/59000.000000
loss: 4.684633, 12832.000000/59000.000000
loss: 4.683852, 13472.000000/59000.000000
loss: 4.677602, 14112.000000/59000.000000
loss: 4.686977, 14752.000000/59000.000000
loss: 4.690102, 15392.000000/59000.000000
loss: 4.689321, 16032.000000/59000.000000
loss: 4.688540, 16672.000000/59000.000000
loss: 4.677602, 17312.000000/59000.000000
loss: 4.683071, 17952.000000/59000.000000
loss: 4.682290, 18592.000000/59000.000000
loss: 4.686977, 19232.000000/59000.000000
loss: 4.686196, 19872.000000/59000.000000
loss: 4.686977, 20512.000000/59000.000000
loss: 4.685414, 21152.000000/59000.000000
loss: 4.686196, 21792.000000/59000.000000
loss: 4.679946, 22432.000000/59000.000000
loss: 4.688540, 23072.000000/59000.000000
loss: 4.691665, 23712.000000/59000.000000
loss: 4.684633, 24352.000000/59000.000000
loss: 4.687758, 24992.000000/59000.000000
loss: 4.680727, 25632.000000/59000.000000
loss: 4.690102, 26272.000000/59000.000000
loss: 4.686196, 26912.000000/59000.000000
loss: 4.679946, 27552.000000/59000.000000
loss: 4.684633, 28192.000000/59000.000000
loss: 4.681508, 28832.000000/59000.000000
loss: 4.686977, 29472.000000/59000.000000
loss: 4.680727, 30112.000000/59000.000000
loss: 4.685414, 30752.000000/59000.000000
loss: 4.684633, 31392.000000/59000.000000
loss: 4.683852, 32032.000000/59000.000000
loss: 4.686196, 32672.000000/59000.000000
loss: 4.684633, 33312.000000/59000.000000
loss: 4.686196, 33952.000000/59000.000000
loss: 4.691665, 34592.000000/59000.000000
loss: 4.683852, 35232.000000/59000.000000
loss: 4.683852, 35872.000000/59000.000000
loss: 4.685414, 36512.000000/59000.000000
loss: 4.685414, 37152.000000/59000.000000
loss: 4.676040, 37792.000000/59000.000000
loss: 4.686196, 38432.000000/59000.000000
loss: 4.685414, 39072.000000/59000.000000
loss: 4.683071, 39712.000000/59000.000000
loss: 4.684633, 40352.000000/59000.000000
loss: 4.686977, 40992.000000/59000.000000
loss: 4.680727, 41632.000000/59000.000000
loss: 4.686977, 42272.000000/59000.000000
loss: 4.691665, 42912.000000/59000.000000
loss: 4.687758, 43552.000000/59000.000000
loss: 4.686196, 44192.000000/59000.000000
loss: 4.687758, 44832.000000/59000.000000
loss: 4.683071, 45472.000000/59000.000000
loss: 4.688540, 46112.000000/59000.000000
loss: 4.688540, 46752.000000/59000.000000
loss: 4.686196, 47392.000000/59000.000000
loss: 4.689321, 48032.000000/59000.000000
loss: 4.690102, 48672.000000/59000.000000
loss: 4.683071, 49312.000000/59000.000000
loss: 4.683071, 49952.000000/59000.000000
loss: 4.688540, 50592.000000/59000.000000
loss: 4.685414, 51232.000000/59000.000000
loss: 4.685414, 51872.000000/59000.000000
loss: 4.688540, 52512.000000/59000.000000
loss: 4.683071, 53152.000000/59000.000000
loss: 4.680727, 53792.000000/59000.000000
loss: 4.686977, 54432.000000/59000.000000
loss: 4.686196, 55072.000000/59000.000000
loss: 4.682290, 55712.000000/59000.000000
loss: 4.685414, 56352.000000/59000.000000
loss: 4.686977, 56992.000000/59000.000000
loss: 4.685414, 57632.000000/59000.000000
loss: 4.686196, 58272.000000/59000.000000
loss: 4.683852, 58912.000000/59000.000000
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  23,  98,  ..., 107, 107, 107],
        [103,  93, 103,  ..., 107, 107, 107],
        [ 93,  35,  95,  ..., 107, 107, 107],
        ...,
        [103,  48, 106,  ..., 107, 107, 107],
        [ 93,  23,  95,  ..., 107, 107, 107],
        [ 31,  95,  85,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  93,  89,  ..., 107, 107, 107],
        [ 91, 106,  77,  ..., 107, 107, 107],
        [ 93,  61,  96,  ..., 107, 107, 107],
        ...,
        [103,  93,  66,  ..., 107, 107, 107],
        [103,  93,  93,  ..., 107, 107, 107],
        [ 93,  74, 106,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[103,  93, 103,  ..., 107, 107, 107],
        [ 89,  26, 105,  ..., 107, 107, 107],
        [101,  93,   5,  ..., 107, 107, 107],
        ...,
        [101, 103,  20,  ..., 107, 107, 107],
        [ 54,  96,  33,  ..., 107, 107, 107],
        [103,  93,  31,  ..., 107, 107, 107]])
tensor([[101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        ...,
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101],
        [101, 101, 101,  ..., 101, 101, 101]])
tensor([[101,  11,  96,  ..., 107, 107, 107],
        [103,  93,  78,  ..., 107, 107, 107],
        [103, 101,  93,  ..., 107, 107, 107],
        ...,
        [101,  18,  89,  ..., 107, 107, 107],
        [103, 101,   8,  ..., 107, 107, 107],
        [ 99, 101,  19,  ..., 107, 107, 107]])
Test Error: 
 Accuracy: 1.2%, Avg loss: 4.686098 