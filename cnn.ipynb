{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "root=\"data\",\n",
    "train=True,\n",
    "download=True,\n",
    "transform=ToTensor())\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "root=\"data\",\n",
    "train=False,\n",
    "download=True,\n",
    "transform=ToTensor())\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3,3), stride=(1,1),padding = 1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(3,3), stride=(1,1),padding = 1)\n",
    "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1),padding = 1) # increase the size. needs pulling to reduce the size: maxpull, average pull\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2),ceil_mode=True)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.fcn1 = nn.Linear(64*4*4, 32)\n",
    "    self.fcn2 = nn.Linear(32, 10)\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.sm = nn.Softmax()\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    x = self.fcn1(self.flatten(x))\n",
    "    x = self.relu(x)\n",
    "    x = self.fcn2(x)\n",
    "    x = self.sm(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()  # setup the model for training\n",
    "  for batch, (X,y) in enumerate(dataloader):\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward() # calculate the gradients\n",
    "    optimizer.step() # step weights according to the rule\n",
    "    optimizer.zero_grad() # delete all gradients data\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), (batch + 1)*len(X)\n",
    "      print(f\"loss: {loss:>5f}, {current:>5f}/{size:>5f}\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()  # setup the model for evaluating. No tracking calculations\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad(): #  No tracking calculations\n",
    "    for X,y in dataloader:\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " --------------------\n",
      "loss: 2.301839, 64.000000/60000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.303567, 6464.000000/60000.000000\n",
      "loss: 2.302335, 12864.000000/60000.000000\n",
      "loss: 2.301841, 19264.000000/60000.000000\n",
      "loss: 2.303193, 25664.000000/60000.000000\n",
      "loss: 2.301507, 32064.000000/60000.000000\n",
      "loss: 2.302319, 38464.000000/60000.000000\n",
      "loss: 2.302873, 44864.000000/60000.000000\n",
      "loss: 2.302573, 51264.000000/60000.000000\n",
      "loss: 2.300181, 57664.000000/60000.000000\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 2.302179 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      " --------------------\n",
      "loss: 2.302282, 64.000000/60000.000000\n",
      "loss: 2.303320, 6464.000000/60000.000000\n",
      "loss: 2.301832, 12864.000000/60000.000000\n",
      "loss: 2.302629, 19264.000000/60000.000000\n",
      "loss: 2.301218, 25664.000000/60000.000000\n",
      "loss: 2.302009, 32064.000000/60000.000000\n",
      "loss: 2.303495, 38464.000000/60000.000000\n",
      "loss: 2.301011, 44864.000000/60000.000000\n",
      "loss: 2.302837, 51264.000000/60000.000000\n",
      "loss: 2.301702, 57664.000000/60000.000000\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 2.302044 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      " --------------------\n",
      "loss: 2.300708, 64.000000/60000.000000\n",
      "loss: 2.302961, 6464.000000/60000.000000\n",
      "loss: 2.303139, 12864.000000/60000.000000\n",
      "loss: 2.302236, 19264.000000/60000.000000\n",
      "loss: 2.302374, 25664.000000/60000.000000\n",
      "loss: 2.301216, 32064.000000/60000.000000\n",
      "loss: 2.305209, 38464.000000/60000.000000\n",
      "loss: 2.300318, 44864.000000/60000.000000\n",
      "loss: 2.301865, 51264.000000/60000.000000\n",
      "loss: 2.300106, 57664.000000/60000.000000\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 2.301895 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      " --------------------\n",
      "loss: 2.302398, 64.000000/60000.000000\n",
      "loss: 2.301074, 6464.000000/60000.000000\n",
      "loss: 2.302522, 12864.000000/60000.000000\n",
      "loss: 2.300308, 19264.000000/60000.000000\n",
      "loss: 2.301039, 25664.000000/60000.000000\n",
      "loss: 2.300058, 32064.000000/60000.000000\n",
      "loss: 2.298874, 38464.000000/60000.000000\n",
      "loss: 2.298811, 44864.000000/60000.000000\n",
      "loss: 2.303152, 51264.000000/60000.000000\n",
      "loss: 2.301538, 57664.000000/60000.000000\n",
      "Test Error: \n",
      " Accuracy: 16.7%, Avg loss: 2.301720 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      " --------------------\n",
      "loss: 2.301599, 64.000000/60000.000000\n",
      "loss: 2.302438, 6464.000000/60000.000000\n",
      "loss: 2.300492, 12864.000000/60000.000000\n",
      "loss: 2.303298, 19264.000000/60000.000000\n",
      "loss: 2.303907, 25664.000000/60000.000000\n",
      "loss: 2.300960, 32064.000000/60000.000000\n",
      "loss: 2.303338, 38464.000000/60000.000000\n",
      "loss: 2.300847, 44864.000000/60000.000000\n",
      "loss: 2.302349, 51264.000000/60000.000000\n",
      "loss: 2.300135, 57664.000000/60000.000000\n",
      "Test Error: \n",
      " Accuracy: 11.3%, Avg loss: 2.301512 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n\", \"-\"*20)\n",
    "  train(train_dataloader, model, loss_fn, optimizer)\n",
    "  test(test_dataloader, model, loss_fn)\n",
    "  print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
